\setlength{\footskip}{8mm}

\chapter{Results}

\label{ch:results}

This chapter describes the results I obtained during this research.
First, the deep neural network model used in the study is described. Then, the results obtained with this network in the context of face verification are given. After that, I describe the final experimental software, which is available online and the results one can expect from it. Finally I describe the results of the program on a particular video of the database.

\section{Preliminary results}
Before the proposal, some parts of the solution had been built.
\begin{itemize}
\item Scripts to generate the database of face images from a video surveillance sequence had been written. The database had been generated and was usable for a direct face identification model. However, the overlap calculation for face detection was not written yet. Hence, the number of available classes was limited, decreasing the performances of a \enquote{Same/Not Same} network. A direct face identification model would not affected by this issue, and it could have been built with this version of the database. The database contained 55,203 images. After manual labeling of the faces in the database, 183 images were labeled 1 for the first researcher, 325 were labeled 2 and 15 were labeled 3.
\item The scripts to generate the database files mentioned in Figure 3.2 were fully written, and worked both for a direct face identification model and for a Siamese network. I executed them for this second scenario. Four files \textt{train1.txt}, \textt{train2.txt}, \textt{test1.txt}, and \textt{test2.txt}, as described in section 3.6.2, had already been built.
\item I designed a Siamese model with Caffe and trained it on the generated database for 50,000 epochs. This training required one night, with batches of size 20, on the 780 GTX GPU card given by the laboratory. The accuracy of the resulting network could not be tested at that moment because of the singular output generated by such a network, as mentioned in section 2.3.1. A script was being written to face this issue.
\end{itemize}

\section{Evolution after the proposal}
After the proposal, the direction taken by the study slightly evolved.
\begin{itemize}
\item A Python script to interpret the results of the Siamese training was written. Its role was to determine a threshold for the distance between two images as described in the previous chapter. The results were not satisfying as the output vector for each image through the Siamese network was always a 0 vector. I hypothesized that the problem was that only the images representing the researchers were labeled.
\item Consequently, I adapted the code for face detection to make it a face tracker. The scripts for the database generation were modified accordingly. Then the Siamese network was trained again considering the fact that there were a large range of classes with few images in each. However, again, the results were not satisfying, and the exact cause of this remains uncertain. An error in the code is improbable, as very similar code was used for digit recognition and worked fine. The most probable cause is the non-convergence of the network.
\item Then, I studied an other network. The idea was to test a pre-trained network on which the MBK database could be used with only minor modifications. A particularly light and efficient face verification network which reached state-of-the-art was selected. The details concerning this network's architecture and the obtained results were particularly interesting and are explained in the next sections.
\end{itemize}

\section{Results on the MBK database}
\subsection{The MBK database}
The MBK database is an experimental database of faces extracted from surveillance videos in the MBK mall in Bangkok. The labeling of the faces is done both through automatic overlapping and manual labeling for the researchers. This leads to around 85,000 images of faces (a first experiment described in the \enquote{Preliminary Results} section lead to around 50,000 images but a new experiment with different parameters lead to the detection of more faces). Few mistakes were made by the automatic process and it was not feasible to correct them. Furthermore, the faces are directly extracted from frames and their resolution is often very poor while their blurriness is important. 
\subsection{Test}
Wu, He and Sun model presented in Section 2.4 and pre-trained for the LFW database, was used to classify the faces in the MBK database surveillance video. It was tested on 13,881 negative pairs and 13,881 positive pairs. The first element of each pair was taken in the direct order of the database. The second element was taken such that each first element was the origin of as many positive and negative pairs. For each label, each positive pair which could have been created was actually created. The negative pairs were chosen randomly.
\subsection{Results}

The calculation of the following curves was made under Matlab using the VLFeat library.

The ROC curve obtained is shown in Figure 4.1. The accuracy of the model is 88.04\%. Here, a decision by the model is graded as correct if it correctly indicates that the input pair is the same person or different people and incorrect if its response to the pair is not correct. To obtain the ROC curves, the threshold for declaring a pair the same varied from 0 (all pairs are different) and 1 (all pairs are assumed the same).


\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.5]{figures/ROC_help.png}  
  \protect\label{fig:mfm}
  \caption[Calculation of the ROC curve by varying the same/different distance threshold. Extracted from Wikipedia.]{Calculation of the ROC curve by varying the same/different distance threshold. Extracted from Wikipedia.}
\end{figure}
\FloatBarrier
\end{itemize}
\FloatBarrier

For a given threshold, some of the pairs that are truly positive are classified as positive (true positives or TPs). Some are considered as positive while they are actually negative (false positives or FPs). Some are considered as negative and are actually negative (true negatives or TNs). Finally, some are considered negative while but are actually positive (false negatives or FNs).\\
The ROC curve is the curve made of all the points determined by a threshold between 0 and 1, for which the abscissa is the false positive rate and for which the ordinate is the true positive rate.\\

The threshold that is usually kept is the one for which we have an equal probability of miss-classifying a positive or negative sample. This point is obtained by finding the intersection of the ROC curve with a diagonal of the unit square. This point is called the EER. In our case, the EER = 11.96\%. The corresponding threshold is 0.14.

\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.7]{figures/result.png}  
  \protect\label{fig:mfm}
  \caption[ROC curve of the network on the MBK database.]{ROC curve of the network on the MBK database.}
\end{figure}
\FloatBarrier
\end{itemize}

We can compare the ROC curve obtained on the MBK database with other newtorks such as DeepFace on the YTF database as shown in the following figure. This comparison is not direct, as the curves do not concern the same databases, but they are both made of face images extracted from videos, so we may conclude that the MBK results are competitive.

\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.4]{figures/result_compared.png}  
  \protect\label{fig:mfm}
  \caption[ROC curve of several networks on the YTF database. Extracted from DeepFace (Taigman, Yang, Ranzato, Wolf, 2014). Our results on MBK compare favorably with these results.]{ROC curve of several networks on the YTF database. Extracted from DeepFace (Taigman, Yang, Ranzato, Wolf, 2014). Our results on MBK compare favorably with these results.}
\end{figure}
\FloatBarrier
\end{itemize}

In figure 4.3, a histogram describing the distribution of the positive and negative pairs relative to their score is also provided. The negative pairs are represented in blue and the positive ones are represented in red. A few errors in the automatic process of determining corresponding faces were made; the details and the consequences of these errors are described in the next section.

\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.5]{figures/histograms.jpg}  
  \protect\label{fig:mfm}
  \caption[Distribution of the positive and negative pairs according to their score.]{Distribution of the positive and negative pairs according to their score.}
\end{figure}
\FloatBarrier
\end{itemize}
\FloatBarrier

The ROC curve can be easily obtained from this histogram. The idea is that a threshold between 0 and 1 separates the histogram as shown in Figure 4.4.

\section{Description of the final product}

The final experimental product proposed at the end of this study is made of several parts.

\subsection{Face detection & overlapping}
As said in the third chapter, the face detection algorithm was written with C++ and OpenCV. The algorithm uses the built-in Haar feature-based cascade classifier. A simple face detector was not enough and a face tracking algorithm providing automatic labeling of the faces had to be written for two reasons:
\begin{itemize}
\item First, to test the network, we needed positive and negative pairs of images. The problem is that there are almost 90,000 images of faces in the database after face detection was done, so it was not possible to create enough positive and negative pairs manually.
\item The second point is described in the last section of this chapter.
\end{itemize}
Consequently, a face tracking algorithm was written. Its behavior is described in the chapter Methodology, section \enquote{Creation of database files.}

The face tracker is efficient enough for this case but no study has been made on its real accuracy. Practically, two errors can be made:
\begin{itemize}
\item A single face appearing in the video may be considered with two different labels.
\item Several faces appearing in the video may be considered with the same label.
\end{itemize}

The first error does not change much about the results of the study. The negative pairs are chosen randomly in the list of all the faces. The possibility that two images from the same person are considered as negative pairs is low. However, the second scenario, more rare but still existing, is more dangerous for the precision of the analysis of the results, as the positive pairs are created with all the available images of the same label. Consequently, the number of pairs considered as positive with a relatively low score may be slightly overestimated, while the number of pairs with a relatively low score may be slightly underestimated. Hence, the global accuracy of the model may be slightly underestimated.

\subsection{Face verification}
After the face detection process is done, the second part of the process can start.
It performs several successive actions.
\begin{itemize}
\item Ask the user to enter the address of a set of images of the person he is looking for in the database.
\item Run those images through the neural network to obtain an array of features (numbers) from each image. The above-mentioned distance between each pair of images can be directly computed as a cosine-score of their two corresponding arrays of features.
\item Ask for the address of the database containing the images of faces extracted from the dataset.
\item The array of features for each image is computed by feeding the image to the neural network. The cosine-score of each image of a detected face with each image of the person the user is looking for is computed. The algorithm decides whether it represents the same person or not by applying a threshold to the cosine score.
\end{itemize}
\subsection{Selection of the best test}
For the rest of this chapter, I will call the detected images from the videos the \enquote{suspect images} and the images provided by the user the \enquote{criminal images.}\\
\\
The initial naive idea was to consider that if the score of a suspect image with each criminal image is above the threshold then the suspect is the criminal, and otherwise he or she is not. The problem is that this idea surely increases the true negative rate in the test, but it also decreases the true positive rate, which is practically not acceptable.\\
\\
This is where automatic labeling becomes particularly useful. Consider a number N of suspect images that we know are from the same person, thanks to the automatic labeling.
Also consider a number n of criminal images.
The problem underlined is \enquote{How many pictures among the N images of suspects have to be identified by at least how many n images of criminals to maximize the accuracy of the model?}

The answer is expressed in terms of probability.
For a given suspect image and a given criminal image, let's call D the event \enquote{a suspect is detected as a criminal in one picture} and call P the event \enquote{the suspect is actually the criminal on the picture}.
Then:\\
\[P(P|D)=\frac{TPR}{TPR+FPR}=p\]
where TPR = True Positive Rate and FPR = False Positive Rate.

If we could assume that the fact that a person is classified as a criminal image based on one picture is independant of the fact that the same suspect image is classified as a criminal image based on another picture. Then the probability that the suspect image is detected k times among the n images of the criminal follows a binomial distribution written as follows:

\[P_{exactly k,n}(P|D)=C^{k}_{n}p^k(1-p)^{n-k}\]

Although the assumption is clearly false, it is a useful approximation, under which the probability that the suspect being detected at least k times among the n images is

\[P_{k,n}(P|D)=\sum_{k'=k}^{k'=n} C^{k'}_{n}p^{k'}(1-p)^{n-k'}=A_{k,n}\]

Assume now that a suspect image being detected at least k times among n images as a criminal image is independent of the fact that an other suspect image with the same label is also detected as a criminal at least k times among n. Then the probability that l suspect images among N suspect images are detected k times among n criminal images also follows a binomial law written:

\[P_{l,N,k,n}(P|D)=\sum_{l'=l}^{l'=N} C^{l'}_{N}A_{k,n}^{l'}(1-A_{l',n})^{N-l'}\]

In conclusion, we have formulated the probability that for a given set of N images of a suspect, he or she is actually a criminal knowing that at least l images are detected as criminals at least k times among the total number of criminal images.\\

This defines a matrix of probabilities M such that:

\[M_{i,j}=P_{i,N,j,n}\]

In a scenario where we have five suspect images and three criminal images, the resulting matrix has the aspect presented in the following picture:


\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.7]{figures/matrix.png}  
  \caption[The matrix of probabilities.]{The matrix of probabilities.}
  \protect\label{fig:Siamese}
\end{figure}
\FloatBarrier
\end{itemize}

Here are the values in the matrix from one test:

[0, 0, 0, 0]\newline
[0, 0.9999999999999951, 0.9999999525689869, 0.9976629875412226]\newline
[0, 0.9999999999823158, 0.9999932742823311, 0.9700927023132484]\newline
[0, 0.9999999742413335, 0.9996171531778806, 0.839991448518568]\newline
[0, 0.9999812348061731, 0.9890255828765551, 0.533024434956926]\newline
[0, 0.9931600804077683, 0.8398962730338903, 0.1708882346261404]\newline

Obviously, this matrix just gives an indication and cannot be trusted. The main reason is that the binomial law is not really applicable because the decisions are not independent. In fact, the suspect images are not so different from one frame to the next. Still, the matrix can give an interesting indication on which test is the best one to work with on the current label.

Theoretically, other cases exist. For example, with two suspect images and three criminal images, how can we decide if the suspect is the criminal and with which accuracy when the first suspect image is never detected as a criminal and the second one is detected three times as a criminal? This case has not been studied.

The final point is that there are other complex and interesting ways to decide whether a suspect is a criminal after the tests. The law of large numbers can be used. Basically if \[Number\_of\_positive\_tests / N \] has a distance to accuracy which is smaller than the distance to \[1-accuracy\] one can conclude that the test is positive.

\subsection{Processing of group of images by label}
Given a label, meaning given a group of suspect images representing one person, the test to decide whether or not the person appearing on the images is the criminal works like this:
\begin{itemize}
\item Let N be the number of suspect images and n the number of criminal images.
\item The matrix mentioned in the previous subsection is computed and the line L and column C corresponding to the value are extracted. The suspect images will have to be detected as criminals at least C times for at least L of them.
\item The tests are made by feeding the images to the neural network. If the minimum conditions given by the previous expression are fulfilled, the algorithm stops and the images are saved in a directory at an address similar to \enquote{Captured\_Faces/VideoX/LabelYFrameZFaceF.jpg}.
\end{itemize} 

When the algorithm is finished, the user has access to all faces detected as criminals and can see, according to the filename the frame number and the name of the video in which he or she is detected. This is precisely filling the goal of the study described in the third section of the third chapter.

\section{A test on a video of the database}
Internal note: The first researcher is Jednipat. The second one is Teeraporn. The third one is Vasan.\\
\\
A test of the software has been done on one video of the database in which the three researchers appear.
9848 faces were detected in the video. 47 of them contained one of our researchers. A picture of this researcher from a different video was provided and compared to each suspect image and no decision taking algorithm as explained in the section \enquote{Selection of the best test} was used. The optimal threshold determined earlier was a bit smaller than the actual one because of the mistakes contained in the face tracker and thus in the test.\\
\\
Figure 4.6 represents the ROC curve of the experiment with the Area Under the Curve and the Equal Error Rate. A frequent false positive case is the test mistaking the first researcher (Figure 3.3 on the left) for the second one (Figure 4.10).

\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.7]{figures/jednipat.jpg}  
  \caption[ROC curve of a test on the first researcher.]{ROC curve of a test on the first researcher.}
  \protect\label{fig:Siamese}
\end{figure}
\FloatBarrier
\end{itemize}

For example, with a threshold of 0.2:
\begin{itemize}
\item 46 out of the 47 pictures of the researcher were detected. The true positive rate is 97.87\%. This score may be quite overestimated by the fact that the given picture of the researcher was very similar to the ones detected in the video.
\item Among the 9801 face images that did not represent our researcher, 762 were detected as positive. Consequently, the false positive rate is 7.77\%.
\item The accuracy of the system on this video in particular is 92.25\%. This result underlines the fact that the global accuracy of the system was underestimated by the errors in the face tracker.
\item The 9848 detected faces of the video which was 1 minute and 14 seconds long, with 30 frames per seconds were processed by the neural network and compared with the picture of the researcher in three hours and twenty minutes on a MacBook Pro with a 2.4GHz Intel Core i5 CPU. Processing was much faster with a GPU using CUDA.
\end{itemize}

A second identical test was made with the second researcher whose face was detected 53 times on the same video. However, this test on the second researcher was made two times. First with a side face for the reference picture. Then with a front face. Figures 4.7 and 4.8 represent the ROC curve of these experiments.

\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.7]{figures/Tee.jpg}  
  \caption[ROC curve of the test on the second researcher with a side face reference image shown in Figure 4.9.]{ROC curve of the test on the second researcher with a side face reference image shown in Figure 4.9.}
  \protect\label{fig:Siamese}
\end{figure}
\FloatBarrier
\end{itemize}

\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.7]{figures/Tee2.jpg}  
  \caption[ROC curve of the test on the second researcher with a front face reference image shown in Figure 4.10.]{ROC curve of the test on the second researcher with a front face reference image shown in Figure 4.10.}
  \protect\label{fig:Siamese}
\end{figure}
\FloatBarrier
\end{itemize}

Figure 4.9 and 4.10 represent the reference pictures used for this experiment.

\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.5]{figures/sidepic.jpg}  
  \caption[Side face reference image, which produced the ROC curve shown in Figure 4.7.]{Side face reference image, which produced the ROC curve shown in Figure 4.7.}
  \protect\label{fig:Siamese}
\end{figure}
\FloatBarrier
\end{itemize}

\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.5]{figures/frontpic.jpg}  
  \caption[Front face reference image, which produced the ROC curve shown in Figure 4.8.]{Front face reference image, which produced the ROC curve shown in Figure 4.8.}
  \protect\label{fig:Siamese}
\end{figure}
\FloatBarrier
\end{itemize}
The test gives considerable better results with a front face picture.\\

A third test was made with one reference image from the third researcher whose face was detected 19 times on the same video. The ROC curve of this test is given in Figure 4.11.

\begin{figure}[!ht]
  \centering
  \includegraphics[scale=0.7]{figures/Vasan.jpg}  
  \caption[ROC curve of the test on the third researcher.]{ROC curve of the test on the third researcher.}
  \protect\label{fig:Siamese}
\end{figure}
\FloatBarrier
\end{itemize}